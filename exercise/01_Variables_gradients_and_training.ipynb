{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "> **tf.Variables** are used when a tensor's **gradient** have to be computed. These are often called **parameters of an algorithm**, that are updated after each training step.\n",
    "\n",
    "> The gradients are computed by **automatic differentiation** on a **DAG**\n",
    "\n",
    "> Consider the example of solving **linear regression in one variable iteratively** : (other methods of solving include - finding the second derivative to compute the learning rate and get a **closed form solution**, or by computing **pseudo inverse**)\n",
    "\n",
    "<img src=\"pics/computational_graph_regression.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing gradients:\n",
    "\n",
    "> Gradient of **output** with respect to a **variable** is the **product of gradients along the path connecting these two nodes**. If there are **more than one path between the nodes** (When least square is computed for a batch of inputs), the gradient is the **sum of the results on all such paths** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholders\n",
    "> **tf.placeholders** are commonly used for **inputs** to the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of x is passed when **running the session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", dtype=float32)\n",
      "Tensor(\"target_1:0\", dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,name=\"input\")\n",
    "t = tf.placeholder(tf.float32,name=\"target\") \n",
    "#takes shape based on feed_dict unless the shape is explicitly specified\n",
    "\n",
    "#Sometimes, we may want to fix certain dimension and the other dimension to be determined at run time\n",
    "#placeholder to handle different catch size\n",
    "batch = tf.placeholder(tf.float32,(None,5))\n",
    "print(x)\n",
    "print(t)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables\n",
    "> Variables have to defined with initial value\n",
    "```bash\n",
    "A = tf.Variable(<initial_value>, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'A_1:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'B_1:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(5, 4) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "A = tf.Variable(1.0,tf.float32,name=\"A\")\n",
    "B = tf.Variable(0.0,tf.float32,name=\"B\")\n",
    "\n",
    "#Initializing a variable with tensor\n",
    "tensor = tf.random_uniform((5,4),0,101)\n",
    "tensor_variable = tf.Variable(tensor)\n",
    "\n",
    "print(A)\n",
    "print(B)\n",
    "print(tensor_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = A*x + B\n",
    "E = tf.reduce_sum(tf.square(tf.subtract(y,t))) \n",
    "#if placeholder is a batch, then y is a vector by pythonbroadcasting rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm tensorboard_logs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./tensorboard_logs', sess.graph)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 1.12.0 at http://0f5261ab9fe2:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=tensorboard_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/graph3.png\" width=300px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Variable have to be **initialized** before running the graph\n",
    "\n",
    "```python\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        ...\n",
    "```\n",
    "\n",
    "> You can also initialize specific variables with\n",
    "```bash\n",
    "init = tf.variable_initializer([A])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session() \n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"GradientDescent_2\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent_2/update_A/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent_2/update_B/ApplyGradientDescent\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(E)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, A, B :  0.92160004 1.02 0.02\n",
      "Loss, A, B :  0.84934676 1.0392 0.0392\n",
      "Loss, A, B :  0.7827579 1.057632 0.057632003\n",
      "Loss, A, B :  0.7213897 1.0753267 0.075326726\n",
      "Loss, A, B :  0.66483265 1.0923136 0.092313655\n",
      "Loss, A, B :  0.6127097 1.1086211 0.108621106\n",
      "Loss, A, B :  0.56467324 1.1242763 0.12427626\n",
      "Loss, A, B :  0.52040285 1.1393052 0.1393052\n",
      "Loss, A, B :  0.4796033 1.153733 0.153733\n",
      "Loss, A, B :  0.4420024 1.1675837 0.16758367\n",
      "Loss, A, B :  0.4073495 1.1808803 0.18088032\n",
      "Loss, A, B :  0.37541324 1.1936451 0.1936451\n",
      "Loss, A, B :  0.34598076 1.2058994 0.2058993\n",
      "Loss, A, B :  0.31885594 1.2176634 0.21766332\n",
      "Loss, A, B :  0.29385763 1.2289568 0.22895679\n",
      "Loss, A, B :  0.2708192 1.2397985 0.23979852\n",
      "Loss, A, B :  0.24958698 1.2502066 0.25020656\n",
      "Loss, A, B :  0.23001932 1.2601984 0.2601983\n",
      "Loss, A, B :  0.21198583 1.2697904 0.26979035\n",
      "Loss, A, B :  0.19536613 1.2789989 0.27899873\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    sess.run(train,feed_dict={x:1,t:2})\n",
    "    #Get the value of the variables after each iteration\n",
    "    loss,a,b = sess.run([E,A,B],feed_dict={x:1,t:2})\n",
    "    print(\"Loss, A, B : \", loss,a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the gradients\n",
    "> The **optimizer.minimize** is actually a wrapper of two methods\n",
    "\n",
    ">> **optimizer.compute_gradients** : With this gradient, custom regularizers can be applied\n",
    "\n",
    ">> **optimizer.apply_gradients**\n",
    "\n",
    "> This format is used to manipulate the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gradients/mul_grad/tuple/control_dependency:0\", shape=(), dtype=float32)\n",
      "<tf.Variable 'A:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "grad_A, grad_B = optimizer.compute_gradients(E,[A,B])\n",
    "print(grad_A[0]) #contains both grad\n",
    "print(grad_A[1]) # and var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_A/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_B/ApplyGradientDescent\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Manipulate grads if needed\n",
    "train = optimizer.apply_gradients([grad_A,grad_B])\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, A, B, Grad_A, Grad_B :  0.92160004 1.02 0.02 -1.9200001 -1.9200001\n",
      "Loss, A, B, Grad_A, Grad_B :  0.84934676 1.0392 0.0392 -1.8432002 -1.8432002\n",
      "Loss, A, B, Grad_A, Grad_B :  0.7827579 1.057632 0.057632003 -1.7694721 -1.7694721\n",
      "Loss, A, B, Grad_A, Grad_B :  0.7213897 1.0753267 0.075326726 -1.6986933 -1.6986933\n",
      "Loss, A, B, Grad_A, Grad_B :  0.66483265 1.0923136 0.092313655 -1.6307454 -1.6307454\n",
      "Loss, A, B, Grad_A, Grad_B :  0.6127097 1.1086211 0.108621106 -1.5655155 -1.5655155\n",
      "Loss, A, B, Grad_A, Grad_B :  0.56467324 1.1242763 0.12427626 -1.5028949 -1.5028949\n",
      "Loss, A, B, Grad_A, Grad_B :  0.52040285 1.1393052 0.1393052 -1.4427791 -1.4427791\n",
      "Loss, A, B, Grad_A, Grad_B :  0.4796033 1.153733 0.153733 -1.3850679 -1.3850679\n",
      "Loss, A, B, Grad_A, Grad_B :  0.4420024 1.1675837 0.16758367 -1.3296652 -1.3296652\n",
      "Loss, A, B, Grad_A, Grad_B :  0.4073495 1.1808803 0.18088032 -1.2764788 -1.2764788\n",
      "Loss, A, B, Grad_A, Grad_B :  0.37541324 1.1936451 0.1936451 -1.2254195 -1.2254195\n",
      "Loss, A, B, Grad_A, Grad_B :  0.34598076 1.2058994 0.2058993 -1.1764026 -1.1764026\n",
      "Loss, A, B, Grad_A, Grad_B :  0.31885594 1.2176634 0.21766332 -1.1293466 -1.1293466\n",
      "Loss, A, B, Grad_A, Grad_B :  0.29385763 1.2289568 0.22895679 -1.0841727 -1.0841727\n",
      "Loss, A, B, Grad_A, Grad_B :  0.2708192 1.2397985 0.23979852 -1.0408058 -1.0408058\n",
      "Loss, A, B, Grad_A, Grad_B :  0.24958698 1.2502066 0.25020656 -0.99917364 -0.99917364\n",
      "Loss, A, B, Grad_A, Grad_B :  0.23001932 1.2601984 0.2601983 -0.9592066 -0.9592066\n",
      "Loss, A, B, Grad_A, Grad_B :  0.21198583 1.2697904 0.26979035 -0.92083836 -0.92083836\n",
      "Loss, A, B, Grad_A, Grad_B :  0.19536613 1.2789989 0.27899873 -0.88400483 -0.88400483\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    sess.run(train,feed_dict={x:1,t:2})\n",
    "    loss,a,b,g_a,g_b = sess.run([E,A,B,grad_A[0],grad_B[0]],feed_dict={x:1,t:2})\n",
    "    print(\"Loss, A, B, Grad_A, Grad_B : \", loss,a,b,g_a,g_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm tensorboard_logs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./tensorboard_logs', sess.graph)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 1.12.0 at http://0f5261ab9fe2:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=tensorboard_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
