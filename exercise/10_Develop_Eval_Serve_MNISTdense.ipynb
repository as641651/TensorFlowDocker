{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop,Evaluavate,Serve MNIST dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('./datasets/MNIST_data/') \n",
    "train_images_path = p / 'train-images.idx3-ubyte'\n",
    "train_label_path = p / 'train-labels.idx1-ubyte'\n",
    "test_images_path = p / 't10k-images.idx3-ubyte'\n",
    "test_label_path = p / 't10k-labels.idx1-ubyte'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Check train image file\n",
    "\n",
    "> First 16 bytes contain 4 int32 numbers having meta info. Remaining are int8 pixel data with 1 byte each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2051, 60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = train_images_path.open('rb')\n",
    "m,n,h,w = np.frombuffer(ft.read(4*4),np.dtype('u4').newbyteorder('>'))\n",
    "m,n,h,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_im = np.frombuffer(ft.read(),np.dtype('u1')).reshape(n,h,w)\n",
    "o_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F27419E56D8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(o_im[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check train label file**\n",
    "\n",
    "> First 8 bytes contain 2 int32 numbers having meta info. Remaining are int8 label data 1 byte each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2049, 60000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = train_label_path.open('rb')\n",
    "m,n = np.frombuffer(ft.read(2*4),np.dtype('u4').newbyteorder('>'))\n",
    "m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = np.frombuffer(ft.read(),np.dtype('u1'))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create read pipeline\n",
    "\n",
    "> Create separate training and test dataset pipeline. Use **Reinitializable** iterator to switch between them. This type of iterators are useful when we want to fine tune the model on different dataset with different preprocessing pipeline\n",
    "\n",
    "> Make it possible not to depend on iterators for serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(train:bool) -> tf.data.Dataset:\n",
    "    if train:\n",
    "        #4 byte offset for 4 numbers\n",
    "        im = tf.data.FixedLengthRecordDataset([str(train_images_path)],28*28,header_bytes=16)\n",
    "        #4 byte offset for 2 numbers\n",
    "        label = tf.data.FixedLengthRecordDataset([str(train_label_path)],1,header_bytes=8)        \n",
    "    else:\n",
    "        im = tf.data.FixedLengthRecordDataset([str(test_images_path)],28*28,header_bytes=16)\n",
    "        label = tf.data.FixedLengthRecordDataset([str(test_label_path)],1,header_bytes=8)\n",
    "        \n",
    "    im = im.map(lambda x: tf.decode_raw(x,tf.uint8),num_parallel_calls=4)\n",
    "    im = im.map(lambda x: tf.reshape(x,(28,28,1)),num_parallel_calls=4) \n",
    "    im = im.map(lambda x: tf.image.convert_image_dtype(x,tf.float32),num_parallel_calls=4)  \n",
    "    \n",
    "    label = label.map(lambda x: tf.decode_raw(x,tf.uint8), num_parallel_calls=4)\n",
    "    label = label.map(lambda x: tf.one_hot(x,10), num_parallel_calls=4)\n",
    "    \n",
    "    dataset = tf.data.Dataset.zip((im,label))\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    train_dataset = mnist_dataset(True)\n",
    "    train_dataset = train_dataset.shuffle(20000)\n",
    "    train_dataset = train_dataset.repeat(10)\n",
    "    train_dataset = train_dataset.batch(10)\n",
    "    train_dataset = train_dataset.prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tf.float32, tf.float32),\n",
       " (TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(1)]),\n",
       "  TensorShape([Dimension(None), Dimension(None), Dimension(10)])))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.output_types,train_dataset.output_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    test_dataset = mnist_dataset(False)\n",
    "    test_dataset = test_dataset.batch(10)\n",
    "    test_dataset = test_dataset.prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tf.float32, tf.float32),\n",
       " (TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(1)]),\n",
       "  TensorShape([Dimension(None), Dimension(None), Dimension(10)])))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.output_types,test_dataset.output_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While creating reinitializable iterator, the output shapes and types of dataset shpuld match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types,train_dataset.output_shapes)\n",
    "im,label = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_init_op = iterator.make_initializer(train_dataset)\n",
    "test_init_op = iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Production** : In this case, dont use iterator (The **if condition** however increases training time by a minor fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_serving = tf.placeholder_with_default(tf.constant(False),[])\n",
    "#Do not use tf.int32 or int64 images! This scales float values close to 0\n",
    "serving_input = tf.placeholder_with_default(np.zeros((1,28,28,1),dtype=np.uint8),(None,28,28,1))\n",
    "serving_input_float = tf.image.convert_image_dtype(serving_input,tf.float32,saturate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using this if cond increases total training(60Kx10 images) time by 2s\n",
    "model_input = tf.cond(is_serving,lambda:serving_input_float,lambda:im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(test_init_op)\n",
    "    i,l = sess.run([model_input,label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f273eab3be0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAADaVJREFUeJzt3X+MXOV1xvHnib1e4jU0GILrGgcnhKA6NDjVxiSCVo4IKZAgEyWhWKrlSpRFLUhQRW2Rq6iWWqUUhSC3SSM5wY1BBGgCCCtx01CrrYVKHS/I2IBpTajT2DVewLQ2AfwDn/6x19EGdt5d5ted9fl+pNXO3HPv3KPrfXzvzDszryNCAPJ5R90NAKgH4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kNT0bu5shvvjJA10c5dAKq/rZzochzyZdVsKv+1LJa2WNE3SNyPiltL6J2lAF/jiVnYJoGBzbJz0uk1f9tueJulrki6TtFDSMtsLm308AN3VynP+xZKejYjnIuKwpHslLW1PWwA6rZXwz5P00zH3d1fLfoHtIdvDtoeP6FALuwPQTh1/tT8i1kTEYEQM9qm/07sDMEmthH+PpPlj7p9ZLQMwBbQS/i2SzrH9XtszJF0taX172gLQaU0P9UXEUds3SPpHjQ71rY2Ip9rWGYCOammcPyI2SNrQpl4AdBFv7wWSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCplmbptb1L0kFJb0g6GhGD7WgKQOe1FP7KxyPixTY8DoAu4rIfSKrV8IekH9p+zPZQOxoC0B2tXvZfFBF7bJ8h6WHbz0TEprErVP8pDEnSSZrZ4u4AtEtLZ/6I2FP9HpH0oKTF46yzJiIGI2KwT/2t7A5AGzUdftsDtk8+flvSJyU92a7GAHRWK5f9cyQ9aPv443w7In7Qlq4AdFzT4Y+I5ySd38ZeAHQRQ31AUoQfSIrwA0kRfiApwg8kRfiBpNrxqb4UXrr2Yw1r71n+bHHbZ0bmFOuHD/UV6/PuKddn7n6lYe3Y1qeL2yIvzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTj/JP0x3/07Ya1zw68XN747BZ3vqRc3nX01Ya11S98vMWdT10/GjmrYW3gtl8qbjt942PtbqfncOYHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQcEV3b2SmeHRf44q7tr51+9rkLGtZe/FD5/9BTd5SP8cu/6mJ9xof+t1i/9bwHGtYueedrxW2//+qsYv1TMxt/V0CrXovDxfrmQwPF+pKTjjS97/d//7pi/QNDW5p+7Dptjo06EPvLf1AVzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kNSEn+e3vVbSpyWNRMR51bLZku6TtEDSLklXRcQEH2qf2ga+u7lQa+2xT2ltc/3NLy9pWPuLCxeU9/2v5TkHbl3y/iY6mpzprx0r1ge27S3WT9t0f7H+azMaz3cwc1d5LoQMJnPm/5akS9+07GZJGyPiHEkbq/sAppAJwx8RmyTtf9PipZLWVbfXSbqyzX0B6LBmn/PPiYjj12TPSyrPRwWg57T8gl+Mfjig4ZvXbQ/ZHrY9fESHWt0dgDZpNvz7bM+VpOr3SKMVI2JNRAxGxGCf+pvcHYB2azb86yWtqG6vkPRQe9oB0C0Tht/2PZIelXSu7d22r5F0i6RLbO+U9InqPoApZMJx/ohY1qA0NT+YfwI6+vy+hrWB+xvXJOmNCR574LsvNdFRe+z7vY8V6x+cUf7z/fL+cxvWFvzdc8VtjxarJwbe4QckRfiBpAg/kBThB5Ii/EBShB9Iiim6UZvpZ80v1r+68qvFep+nFevfWf2JhrXT9j5a3DYDzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTj/KjNM384r1j/SH95pumnDpenH5/99Ktvu6dMOPMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKM86OjDn3qIw1rj3/u9gm2Ls/w9Ps33lisv/PffjTB4+fGmR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkppwnN/2WkmfljQSEedVy1ZJulbSC9VqKyNiQ6eaxNT135c1Pr/Mcnkcf9l/XVKsz/zBE8V6FKuYzJn/W5IuHWf57RGxqPoh+MAUM2H4I2KTpP1d6AVAF7XynP8G29tsr7V9ats6AtAVzYb/65LOlrRI0l5JtzVa0faQ7WHbw0d0qMndAWi3psIfEfsi4o2IOCbpG5IWF9ZdExGDETHYN8EHNQB0T1Phtz13zN3PSHqyPe0A6JbJDPXdI2mJpNNt75b0Z5KW2F6k0dGUXZKu62CPADpgwvBHxLJxFt/RgV4wBb3j5JOL9eW/8UjD2oFjrxe3HfnS+4r1/kNbinWU8Q4/ICnCDyRF+IGkCD+QFOEHkiL8QFJ8dTdasnPVB4v1753+tw1rS3d+trht/waG8jqJMz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJMU4P4r+73c+Wqxv++2/LtZ/fPRIw9orf3Vmcdt+7S3W0RrO/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOP8yU2f9yvF+k1fvK9Y73f5T+jqJ5Y3rL37H/i8fp048wNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUhOO89ueL+lOSXMkhaQ1EbHa9mxJ90laIGmXpKsi4uXOtYpmeHr5n/j87+0u1j8/66Vi/e6DZxTrc77Y+PxyrLglOm0yZ/6jkr4QEQslfVTS9bYXSrpZ0saIOEfSxuo+gCliwvBHxN6IeLy6fVDSDknzJC2VtK5abZ2kKzvVJID2e1vP+W0vkPRhSZslzYmI49+z9LxGnxYAmCImHX7bsyTdL+mmiDgwthYRodHXA8bbbsj2sO3hIzrUUrMA2mdS4bfdp9Hg3x0RD1SL99meW9XnShoZb9uIWBMRgxEx2Kf+dvQMoA0mDL9tS7pD0o6I+MqY0npJK6rbKyQ91P72AHTKZD7Se6Gk5ZK2295aLVsp6RZJf2/7Gkk/kXRVZ1pES84/t1j+8zPuaunhv/alzxfr73ri0ZYeH50zYfgj4hFJblC+uL3tAOgW3uEHJEX4gaQIP5AU4QeSIvxAUoQfSIqv7j4BTFv4gYa1oXtbe+/VwrXXF+sL7vr3lh4f9eHMDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJMc5/AnjmD05tWLti5oGGtck4818Ol1eIcb+9DVMAZ34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIpx/ing9SsWF+sbr7itUJ3Z3mZwwuDMDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJTTjOb3u+pDslzZEUktZExGrbqyRdK+mFatWVEbGhU41m9j8XTivW3zO9+bH8uw+eUaz3HSh/np9P809dk3mTz1FJX4iIx22fLOkx2w9Xtdsj4sudaw9Ap0wY/ojYK2lvdfug7R2S5nW6MQCd9bae89teIOnDkjZXi26wvc32WtvjfpeU7SHbw7aHj+hQS80CaJ9Jh9/2LEn3S7opIg5I+rqksyUt0uiVwbhvMI+INRExGBGDfepvQ8sA2mFS4bfdp9Hg3x0RD0hSROyLiDci4pikb0gqf/oEQE+ZMPy2LekOSTsi4itjls8ds9pnJD3Z/vYAdMpkXu2/UNJySdttb62WrZS0zPYijY727JJ0XUc6REv+8qWFxfqjv7WgWI+929vYDXrJZF7tf0SSxykxpg9MYbzDD0iK8ANJEX4gKcIPJEX4gaQIP5CUo4tTLJ/i2XGBL+7a/oBsNsdGHYj94w3NvwVnfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iqqvj/LZfkPSTMYtOl/Ri1xp4e3q1t17tS6K3ZrWzt7Mi4t2TWbGr4X/Lzu3hiBisrYGCXu2tV/uS6K1ZdfXGZT+QFOEHkqo7/Gtq3n9Jr/bWq31J9NasWnqr9Tk/gPrUfeYHUJNawm/7Utv/YftZ2zfX0UMjtnfZ3m57q+3hmntZa3vE9pNjls22/bDtndXvcadJq6m3Vbb3VMduq+3La+ptvu1/tv207ads31gtr/XYFfqq5bh1/bLf9jRJ/ynpEkm7JW2RtCwinu5qIw3Y3iVpMCJqHxO2/ZuSXpF0Z0ScVy27VdL+iLil+o/z1Ij4kx7pbZWkV+qeubmaUGbu2JmlJV0p6XdV47Er9HWVajhudZz5F0t6NiKei4jDku6VtLSGPnpeRGyStP9Ni5dKWlfdXqfRP56ua9BbT4iIvRHxeHX7oKTjM0vXeuwKfdWijvDPk/TTMfd3q7em/A5JP7T9mO2hupsZx5xq2nRJel7SnDqbGceEMzd305tmlu6ZY9fMjNftxgt+b3VRRPy6pMskXV9d3vakGH3O1kvDNZOaublbxplZ+ufqPHbNznjdbnWEf4+k+WPun1kt6wkRsaf6PSLpQfXe7MP7jk+SWv0eqbmfn+ulmZvHm1laPXDsemnG6zrCv0XSObbfa3uGpKslra+hj7ewPVC9ECPbA5I+qd6bfXi9pBXV7RWSHqqxl1/QKzM3N5pZWjUfu56b8Toiuv4j6XKNvuL/Y0l/WkcPDfp6n6Qnqp+n6u5N0j0avQw8otHXRq6RdJqkjZJ2SvonSbN7qLe7JG2XtE2jQZtbU28XafSSfpukrdXP5XUfu0JftRw33uEHJMULfkBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkvp/uK0ZUt56JeQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(i[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is a float image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[0].min(),i[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([7]),)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(l[0][0]==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check serving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABn0lEQVR4nHWSsWsUURDGf/Pe233v7t56QQJKEEECChZBgqIWV9qksLCy9u8QwUbbtDb+DRYigmAjgiKx0QQEDRKsJOpFo7e527djsUd0F/K1P+abmW8GomAwMMABlpYMRCgwWOPbiF7wDiBrCk0HExgO8AQBm7XIccjxnADywndaIhCd3U5Pl4DoWswuRANW9X2wzrYnMna8HyjSgz1XapWkY5s5+rhb03QSTA43y5erHGsqJdUkqk8TU0fqmNk1d/Vs/jMHMK6uqWDzNc+W+v3vs1OjUoKSGte5+8bXcousJ3e0Gq/JfCcBC57rO6qP7l55sqsHH0/TO8zWwUCQ7T9aa6mz8at/sVvUUslQLz9Mk/rLcxdf0G+6CaGU/EAUvFxT/bD82K28I5u1U7QeCNxL5UUc7TQyKHKG2e+JniGEec+5Eu6Xpb60N90PlFUnxkUCA9Znejs2G/4nh7ew+lnfLIAj0KHElW86vUFw0L5rYBjP6Y+0cx4y1/2IRS7sTnR9OUcgdmAxeqt6f8QRKmw4gmS5Ezg8R1eCl/aQfwFG/HlJxVV8BAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=28x28 at 0x7F273805B400>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open('pics/img_13.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we dont use iterators, error was thrown when one of them were not initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "test_im1 = np.asarray(Image.open('pics/img_13.jpg')).reshape(1,28,28,1)\n",
    "test_im2 = np.asarray(Image.open('pics/img_24.jpg')).reshape(1,28,28,1)\n",
    "test_ims = np.concatenate((test_im1,test_im2),axis=0) #(2,28,28,1)\n",
    "print(test_ims.shape)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(test_init_op) #Throws error when one of the iterators are not initialized\n",
    "    it = sess.run(model_input,{is_serving:True,serving_input:test_ims})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, (2, 28, 28, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it[0].min(), it[0].max(), it.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2738078e48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAEqpJREFUeJzt3X9sVed5B/Dvc6+vcWxssIEwSkiglDQjUUdSl2xKmiVjjdKoFYm6ofJHRSYWV1GirVKlFTFV449Nirb8ENK6rnShgSpNWqXJgjqahKKsUSbEcBBJoIRAUpLAjIFAwGCMr+999odPIpP4PO/lnnvPueb5fiRk+z733PP62l/OvX7OeV9RVRCRP7msB0BE2WD4iZxi+ImcYviJnGL4iZxi+ImcYviJnGL4iZxi+ImcakpzZ80ySVvQFluXfN7cXkulWg+pIST+vkWMjet8Bqex69H913f3dKEhnMWwng/9VAAkDL+I3AFgLYA8gP9Q1Qet+7egDTfKkth6fkqnub/Shx/GF0O/5Dk7YCgHAmZtH9o2IN8xxayXPjxl1qXQHFvT4nBVY6qUNNm/QjoyUtf904W269aK71v1y34RyQP4AYCvAlgIYLmILKz28YgoXUne8y8GcEBV31HVYQBPAVham2ERUb0lCf9sAO+P+fpQdNsFRKRHRHpFpLeI8wl2R0S1VPe/9qvqOlXtVtXuAibVe3dEVKEk4T8MYM6Yr6+IbiOiCSBJ+HcAWCAi80SkGcA3AWyqzbCIqN6qbvWp6oiIPADgBYy2+tar6p4kgymdOh3aadWPnZ/SYe/75En7AYx2Xn5al/3YH5yw66fP2PsO0XJ8LdDizLXYb8XKg4P2rtnKm7AS9flVdTOAzTUaCxGliKf3EjnF8BM5xfATOcXwEznF8BM5xfATOZXq9fySyyE3uT3+DmWjXw2YfX4t2v3mYB8/gVAfXybZvXQ9b1/zYF2yCyS7bDfUxw9eslsOnHuR8HJnqh8e+YmcYviJnGL4iZxi+ImcYviJnGL4iZxKtdWn5TLKAwN1eexcW/yU4EC4HZafMcPegbF9cHbd0NTc9p4hzQV7+5GiUazv3NlSCLQCz7PV16h45CdyiuEncorhJ3KK4SdyiuEncorhJ3KK4SdyKt1LegtNaJrxB7H1kb4j1T94wuW79exZs25d+to090pz25GD71U1po/3HRhbrqUltiZtrea2em7Irg/b50eELkemxsUjP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTifr8InIQwACAEoARVe227q/FEbuXL2Lv0Lg2vTxk96vznZ1mvXzG7qVbU1ivePG35rZ3t9lTe//lgTvN+vBKu1dfOvD7+GLgeQlJ+rwlmVac6qsWJ/ncpqrHa/A4RJQivuwncipp+BXAiyLyqoj01GJARJSOpC/7b1bVwyJyOYAtIvKmqr489g7Rfwo9ANAC+70rEaUn0ZFfVQ9HH48CeBbA4nHus05Vu1W1uwB7zToiSk/V4ReRNhFp/+hzALcD2F2rgRFRfSV52T8TwLMy2p5rAvAzVX2+JqMiorqrOvyq+g6AP7qojcTul+emddnbD8fPT186ddrcNOkS3da4l0225+0H7Hn7b52+z6y/0DfbrJvLaEvgxZ3ay6KHrtdnH3/iYquPyCmGn8gphp/IKYafyCmGn8gphp/IqXSn7oaYbalS/9GqHzvf0WHWS6ftVmA+0GYsfRB/We7n/vsec9vNN/3ArLfm7HZZaOpu5IxWYjlZK04m8azMSxWP/EROMfxETjH8RE4x/EROMfxETjH8RE4x/EROpdrnV1Vziu1gT7kcP3V3sI8fOg/A6OMDgBSaY2utr9rTk33mFvuS3r/qeN+sPzfvS2Z95PfvmnWTdY4AkHjpc8ux+/7ErG9d/bBZ//6R28z6m393bWwt/9JOc9v89GlmvXT8A7M+EfDIT+QUw0/kFMNP5BTDT+QUw0/kFMNP5BTDT+RUqn1+AOYy3FocqdtudSTZY1tTVE99237s/pJdn19osXdetqfXtpbRDk5ZXrb7+LnOGWZdTwQe3zhPoHi7PeV5a65g1td+ZptZ/9I1N8TWZm6zn/NQHz/XYm8fWjK+EfDIT+QUw0/kFMNP5BTDT+QUw0/kFMNP5BTDT+RUsM8vIusBfA3AUVW9LrqtC8DPAcwFcBDAMlUNr4EtAmmOvy4+tBx0Ejpcv6Wk23sPm/XvvXeXWX96/m/M+i2/etOsv3TP4thafn+y6/FH+o4k2j6/8OrY2pprf2Vue6xk/z5c0TTZrJdajHNKNH5uiEokPW+kEVRy5H8cwB2fuG0VgK2qugDA1uhrIppAguFX1ZcBfHKam6UANkSfbwBgH9qIqOFU+55/pqr2RZ8fATCzRuMhopQkPrdfVVVEYt9AiUgPgB4AaIE91x0RpafaI3+/iMwCgOhj7AqbqrpOVbtVtbsggQtYiCg11YZ/E4AV0ecrADxXm+EQUVqC4ReRJwFsA/B5ETkkIisBPAjgKyKyH8CfR18T0QQSfM+vqstjSktqPJa6qmdfduSQ3ee/tqNo1v/3vF3vmfqaWZ/80/hrxzcttOefD62VkGtvN+vlM2fM+lsru2Jr35hsr7VwXu2xvVU8a9YvOxo/D0LovI9cq/33qXqeN5IWnuFH5BTDT+QUw0/kFMNP5BTDT+QUw0/kVLpTd6vWrUUiTfa3krTVZ7V+yoOD5ra/fuQWs774+2/b9Un2NND3T41f4vvpLfHTVwPAe3tmmfUrn7cvCW5bdcisP33VWqNqt/KG1P6Z7Ri60qx37YyffrsUuqQ3by9d7uWSXiK6BDH8RE4x/EROMfxETjH8RE4x/EROMfxETknSKYwvRod06Y1iXAmcs3ur1nLSUoifEhywl9iuRH7qlNha6ZR9aSpCz7GxbDkArNz3jlm/9bL/i61dnm8zty1pYPlvsY8PJ0v2OQ6d+fjzIwbL9s/kUMm+1PlHx79s1nd/0f7eLkXbdStO6wn7FyrCIz+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RU+lezx8ghcA1+eeNa8sD/eqk1/vrsNFzDvTC89Pjp68GgNKxY2Z9wxK7n73qny6Pre1d8iNz2xOBZbCn5y8z65sH55j1/zr+hdjaz+a9ZG57VeD8h2d6v2jWr8aO2Fq+o8PctnTaPncjNOV5PZebrxUe+YmcYviJnGL4iZxi+ImcYviJnGL4iZxi+ImcCvb5RWQ9gK8BOKqq10W3rQFwL4CPGtSrVXVz0sEEe/FG71RL9vzyucvsfnWoz18+d87Y2L5eP9THDyl/cMKsf/6+k7G1W77xN/aDh6YaCHxvnbvtfvipa+L76YMPvWBu25qz52hYsNG+3t/ioY8fUsmR/3EAd4xz+6Oquij6lzj4RJSuYPhV9WUA9qGHiCacJO/5HxCR10VkvYh01mxERJSKasP/QwDzASwC0Afg4bg7ikiPiPSKSG8RE/99EtGloqrwq2q/qpZUtQzgxwAWG/ddp6rdqtpdCCzMSETpqSr8IjJ2ade7AeyuzXCIKC2VtPqeBHArgOkicgjAPwC4VUQWYbRRdBDAt+s4RiKqg2D4VXX5ODc/VoexoHz2bPUbB/rR5UF7fvmkj28KXJcugbXgQ6znberGbYkeO9dmz/sf+pkduffG2FpB7O87tCZAqcXe3vrlDq7zEOrjB36miX5fUsIz/IicYviJnGL4iZxi+ImcYviJnGL4iZxqqKm7L1XSnKytFLrcOD8tfmpwPWu3y8pDQ2ZdWuOX2AYACYztf74ee+Y3TpXtdtn0wPLizf12m9GazF2aC+a2oXqitnSD4JGfyCmGn8gphp/IKYafyCmGn8gphp/IKYafyCn2+VOgRbsXHhK6/LRkTO2da2+3HzzQ50fZnhJ9aEn8EtwAsK8Yv0z2nCZ7+uxBPWPWy612L97cNtCnDz3nlwIe+YmcYviJnGL4iZxi+ImcYviJnGL4iZxi+ImcYp8/DYFeedMVs836yKHDZt2aXrs8MGBum586xaxb5xAAwLt/8VmzvnhS/HkErbnJ5rafe+I+s371/jfNuv2s27Q4bN+BU3cT0UTF8BM5xfATOcXwEznF8BM5xfATOcXwEzkV7POLyBwAGwHMBKAA1qnqWhHpAvBzAHMBHASwTFVP1m+oE1fo2vBgHz8wd35wOWlD6cNTdv22G8z6o19+yqy35uK/99X99lwAVz/0tlkvnaz+1y24RHegzx/6mUyEef0rOfKPAPiuqi4E8McA7heRhQBWAdiqqgsAbI2+JqIJIhh+Ve1T1Z3R5wMA9gKYDWApgA3R3TYAuKtegySi2ruo9/wiMhfA9QC2A5ipqn1R6QhG3xYQ0QRRcfhFZDKAXwL4jqpeMPmaqipG/x4w3nY9ItIrIr1FVP/elIhqq6Lwi0gBo8F/QlWfiW7uF5FZUX0WgKPjbauq61S1W1W7C5hUizETUQ0Ewy8iAuAxAHtV9ZExpU0AVkSfrwDwXO2HR0T1UsklvTcB+BaAN0RkV3TbagAPAviFiKwE8C6AZfUZ4sQXahuF2k7lQXuZbUu+s9OsF6+9yqw/8pN/M+tfaG4x62fK8Zf0vvivN5nbTuvfZtatS5kBQIeL8bXQJbsB1mNPFMHwq+orAOIuXl5S2+EQUVp4hh+RUww/kVMMP5FTDD+RUww/kVMMP5FTnLo7BaF+dOjyz/yMGfYORuKXAC/Pt6cF3/KLx8363uGyWS+qPUH2b4emxtam7Ul22Wtwme1J8WeUBpfgVvv7TnqeQCPgkZ/IKYafyCmGn8gphp/IKYafyCmGn8gphp/IKfb5UxDqRyddorv8p9fH1v7l8X83tz1eij9HAAD+sNk+R2He839t1q9ZG/+95/a9ZW5rd9oRXCY7yZTmoXkQkkwb3ih45CdyiuEncorhJ3KK4SdyiuEncorhJ3KK4Sdyin3+BqDnzpn1oa8vNut/9o+vxNYWGde0j7Lr8/6zx6xf+Wv70cuv7Q3sPwEdd4W4mrgU+vghPPITOcXwEznF8BM5xfATOcXwEznF8BM5xfATOSUa6JWKyBwAGwHMBKAA1qnqWhFZA+BeAMeiu65W1c3WY3VIl94oXNW71vLTumJr5VOnzW2tue2B8FwE1Fi261ac1hP2RAeRSk7yGQHwXVXdKSLtAF4VkS1R7VFVfajagRJRdoLhV9U+AH3R5wMisheAPfUMETW8i3rPLyJzAVwPYHt00wMi8rqIrBeRcec9EpEeEekVkd4iqp9WiYhqq+Lwi8hkAL8E8B1VPQ3ghwDmA1iE0VcGD4+3naquU9VuVe0uBM4jJ6L0VBR+ESlgNPhPqOozAKCq/apaUtUygB8DsK8+IaKGEgy/iAiAxwDsVdVHxtw+a8zd7gawu/bDI6J6qeSv/TcB+BaAN0RkV3TbagDLRWQRRtt/BwF8uy4jvASE2mkSmoK6ZE9iXTphXH4aaOWqsbx3JXLt7Wa9PDCQ6PGpfir5a/8rAMb77TR7+kTU2HiGH5FTDD+RUww/kVMMP5FTDD+RUww/kVOcujsFoaWigxNQB84DsHr5udZWc9NyYNpwaSrY27OPP2HxyE/kFMNP5BTDT+QUw0/kFMNP5BTDT+QUw0/kVHDq7pruTOQYgHfH3DQdwPHUBnBxGnVsjTougGOrVi3HdpWqzqjkjqmG/1M7F+lV1e7MBmBo1LE16rgAjq1aWY2NL/uJnGL4iZzKOvzrMt6/pVHH1qjjAji2amUytkzf8xNRdrI+8hNRRjIJv4jcISL7ROSAiKzKYgxxROSgiLwhIrtEpDfjsawXkaMisnvMbV0iskVE9kcfx10mLaOxrRGRw9Fzt0tE7sxobHNE5CUR+Z2I7BGRv41uz/S5M8aVyfOW+st+EckDeAvAVwAcArADwHJV/V2qA4khIgcBdKtq5j1hEbkFwBkAG1X1uui2fwZwQlUfjP7j7FTV7zXI2NYAOJP1ys3RgjKzxq4sDeAuAPcgw+fOGNcyZPC8ZXHkXwzggKq+o6rDAJ4CsDSDcTQ8VX0ZwIlP3LwUwIbo8w0Y/eVJXczYGoKq9qnqzujzAQAfrSyd6XNnjCsTWYR/NoD3x3x9CI215LcCeFFEXhWRnqwHM46Z0bLpAHAEwMwsBzOO4MrNafrEytIN89xVs+J1rfEPfp92s6reAOCrAO6PXt42JB19z9ZI7ZqKVm5OyzgrS38sy+eu2hWvay2L8B8GMGfM11dEtzUEVT0cfTwK4Fk03urD/R8tkhp9PJrxeD7WSCs3j7eyNBrguWukFa+zCP8OAAtEZJ6INAP4JoBNGYzjU0SkLfpDDESkDcDtaLzVhzcBWBF9vgLAcxmO5QKNsnJz3MrSyPi5a7gVr1U19X8A7sToX/zfBvD3WYwhZlyfBfBa9G9P1mMD8CRGXwYWMfq3kZUApgHYCmA/gN8A6Gqgsf0UwBsAXsdo0GZlNLabMfqS/nUAu6J/d2b93BnjyuR54xl+RE7xD35ETjH8RE4x/EROMfxETjH8RE4x/EROMfxETjH8RE79P96rOtwROPYSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(it[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.layers.dense()**\n",
    "\n",
    "> **units** : Number of output units\n",
    "\n",
    "> **activation**: (Default:No activation) Eg, tf.nn.relu  (No brackets in the end)\n",
    "\n",
    "> **kernel_initializer**: (Default:glorot_uniform). Initializer for **W** Eg. tf.initializers.glorot_normal() (Need brackets in the end)\n",
    "\n",
    "> **bias_initializer** : (Default: zeros) Initializer for **b**\n",
    "\n",
    "> **kernel_regularizer** : (Default:None) Regularizer for **W**. Reg term should be manually added to the final loss\n",
    "\n",
    "> **bias_regularizer** : (Default:None) Regularizer for **b**. Eg. tf.contrib.layers.l2_regularizer(scale=0.01)\n",
    "\n",
    "> **activity regularizer**: (Default:None) Allows regularizer of the output from the layer to be computed.  \n",
    "\n",
    ">> Adding regularization to the loss,\n",
    "```bash\n",
    "l2_loss = tf.losses.get_regularization_loss()\n",
    "....\n",
    "loss += l2_loss\n",
    "```\n",
    "\n",
    "> **kernel/bias constraint** : TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_model(model_input):\n",
    "    \n",
    "    x = tf.reshape(model_input,(-1,784)) \n",
    "    #x = tf.layers.Flatten()(model_input) #Flattens input preserving batch axis (axis 0)\n",
    "    #x = tf.reshape(model_input,(tf.shape(model_input)[0],784)) # use tf.shape(tensor)[0] instead of tensor.shape[0]\n",
    "    \n",
    "    h1 = tf.layers.dense(x,300, \n",
    "                         activation=tf.nn.relu,\n",
    "                         kernel_initializer=tf.initializers.glorot_normal(),\n",
    "                         bias_initializer=tf.initializers.zeros(),\n",
    "                         kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=0.01))\n",
    "    \n",
    "    out = tf.layers.dense(h1,10,kernel_initializer=tf.initializers.glorot_normal()) #No activation\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_3/BiasAdd:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_net = dense_model(model_input)\n",
    "dense_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**While reshaping tensors**, get batchsize with **tf.shape(tensor)[0]** instead of **tensor.shape[0]**. This is because the former returns a tensor, while the latter returns just a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(dense_net.shape[0])\n",
    "print(tf.shape(dense_net)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14736083,  0.15739697,  0.4255202 ,  0.21601763,  0.10804106,\n",
       "         0.05904906, -0.18536016, -0.2624309 ,  0.0244064 , -0.18905488],\n",
       "       [-0.21700291,  0.42048335,  0.6769599 ,  0.51332116,  0.41218263,\n",
       "         0.02299327,  0.32972854,  0.24896121, -0.11314335,  0.10555178],\n",
       "       [-0.25837803,  0.52456355,  0.46733457,  0.39432064,  0.50259936,\n",
       "         0.18293089,  0.34434196, -0.18673882, -0.21897668, -0.35666186],\n",
       "       [-0.23426515,  0.04673613, -0.21403137,  0.8874429 ,  0.08083277,\n",
       "        -0.22781137,  0.18967378, -0.57431644, -0.6072147 , -0.02435531],\n",
       "       [-0.04151042,  0.31907618,  0.54420996,  0.44829866,  0.2622022 ,\n",
       "         0.429591  ,  0.20859638, -0.4092716 ,  0.12350178, -0.11392079],\n",
       "       [-0.6556285 ,  0.2240897 ,  0.2791906 , -0.04154807,  0.19419092,\n",
       "         0.31879625,  0.10711156,  0.2422457 ,  0.28375113, -0.11444634],\n",
       "       [-0.3484749 ,  0.144929  ,  0.59265554,  0.3558277 ,  0.5273468 ,\n",
       "         0.06085622, -0.10796385, -0.3324772 , -0.03429583, -0.12352192],\n",
       "       [-0.61287254,  0.07606147,  0.11627381,  0.2797766 ,  0.3345449 ,\n",
       "         0.2283576 ,  0.00867081,  0.30493715,  0.07256067, -0.06288043],\n",
       "       [ 0.13108787,  0.5610473 ,  0.44291466,  0.81038076,  0.5237605 ,\n",
       "         0.57588375,  0.78035337, -0.1266483 ,  0.40034223, -0.16631842],\n",
       "       [-0.10980871, -0.02342219,  0.35114452,  0.47009692, -0.02680681,\n",
       "         0.4595723 ,  0.42788535,  0.15236926, -0.18975174, -0.87642896]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(training_init_op)\n",
    "    o = sess.run(dense_net)\n",
    "o #(Batch size x 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label,logits=dense_net))\n",
    "#l2_loss = tf.losses.get_regularization_loss()\n",
    "#loss += l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4823198\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(training_init_op)\n",
    "    print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Train model\n",
    "\n",
    "> **IMPORTANT**: After training the model inside a session, **SAVE IT**. While evaluvating in a different session, we are **not supposed to init global variables**!. This will reset all weights!\n",
    "\n",
    "**Create session and train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm models/MNIST_DENSE/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  5000 0.4343119\n",
      "Batch:  10000 0.24396384\n",
      "Batch:  15000 0.19164142\n",
      "Batch:  20000 0.16165522\n",
      "Batch:  25000 0.13965178\n",
      "Batch:  30000 0.122965746\n",
      "Batch:  35000 0.10801165\n",
      "Batch:  40000 0.098606504\n",
      "Batch:  45000 0.08763712\n",
      "Batch:  50000 0.08148293\n",
      "Batch:  55000 0.07459791\n",
      "Batch:  60000 0.069086395\n",
      "Elapsed time :  42.52098560333252  s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(training_init_op)\n",
    "\n",
    "    start = time.time()\n",
    "    try:\n",
    "        i = 1\n",
    "        tmp = []\n",
    "        while True:\n",
    "            i = i+1\n",
    "            l,_ = sess.run([loss,train])\n",
    "            tmp.append(l)\n",
    "            if i%5000 == 0:\n",
    "                avg_loss = np.array(tmp).mean()\n",
    "                print(\"Batch: \",i,avg_loss)\n",
    "                tmp = []\n",
    "                \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    print(\"Elapsed time : \", elapsed, \" s\")\n",
    "    saver.save(sess,'models/MNIST_DENSE/mnist_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation :** Elapsed time is two seconds more when the **if condition** for serving is used "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Evaluvate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predict:'eg: [2,4,1,...]',true: 'eg: [2,4,1,...]') -> int:\n",
    "    correct_pred = tf.equal(predict,true)\n",
    "    #We have to cast [True,False,True,...] --> [1,0,1...]\n",
    "    acc = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Closer look at argmax reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/MNIST_DENSE/mnist_model.ckpt\n",
      "(10, 1)\n",
      "[[7]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [4]\n",
      " [1]\n",
      " [4]\n",
      " [9]\n",
      " [5]\n",
      " [9]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'models/MNIST_DENSE/mnist_model.ckpt')\n",
    "    sess.run(test_init_op)\n",
    "    #label is (10x(1x10)) --> reduced to 10x1\n",
    "    o = sess.run(tf.argmax(label,axis=2))\n",
    "    print(o.shape)\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/MNIST_DENSE/mnist_model.ckpt\n",
      "(10,)\n",
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'models/MNIST_DENSE/mnist_model.ckpt')\n",
    "    sess.run(test_init_op)\n",
    "    #sm = tf.nn.softmax(dense_net) #We get the same answer. max(sm) = max(logit)\n",
    "    #densenet is 10x10 --> reduced to 10\n",
    "    o = sess.run(tf.argmax(dense_net,axis=1))\n",
    "    print(o.shape)\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**:\n",
    "\n",
    "> While using **tf.equal** we have to keep the **broadcasting rule** in mind\n",
    "```bash\n",
    "labels:    10x1\n",
    "dense_net:   10\n",
    "RESULT :   10x10\n",
    "```\n",
    "Therefore, **transpose labels** to get **1x10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/MNIST_DENSE/mnist_model.ckpt\n",
      "[[ True  True  True  True  True  True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'models/MNIST_DENSE/mnist_model.ckpt')\n",
    "    sess.run(test_init_op)\n",
    "    pred = tf.argmax(dense_net,axis=1) #(10x1)\n",
    "    true = tf.argmax(label,axis=2)# (1x10)\n",
    "    correct_pred = tf.equal(pred,tf.transpose(true)) #Without transpose, we get 10x10 bool matrix\n",
    "    print(sess.run(correct_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**:\n",
    "> Dont create new tensors inside a loop! This will slow down everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/MNIST_DENSE/mnist_model.ckpt\n",
      "100 Mean Acc :  0.97700006\n",
      "200 Mean Acc :  0.9560001\n",
      "300 Mean Acc :  0.96099997\n",
      "400 Mean Acc :  0.97099996\n",
      "500 Mean Acc :  0.9660001\n",
      "600 Mean Acc :  0.97900003\n",
      "700 Mean Acc :  0.98300004\n",
      "800 Mean Acc :  0.991\n",
      "900 Mean Acc :  0.99\n",
      "1000 Mean Acc :  0.97099996\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'models/MNIST_DENSE/mnist_model.ckpt')\n",
    "    sess.run(test_init_op)\n",
    "    \n",
    "    #IMPORTANT:\n",
    "    #Dont place this code inside the loop! This will slow down everything\n",
    "    acc = get_accuracy(tf.argmax(dense_net,axis=1),tf.transpose(tf.argmax(label,axis=2)))\n",
    "    \n",
    "    try:\n",
    "        i = 0\n",
    "        acc_list = []\n",
    "        while True:\n",
    "            i = i+1\n",
    "            a = sess.run(acc)\n",
    "            acc_list.append(a)\n",
    "            if i%100 == 0:\n",
    "                print(i, \"Mean Acc : \", np.array(acc_list).mean())\n",
    "                acc_list = []\n",
    "                           \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Serve model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We test the following images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABn0lEQVR4nHWSsWsUURDGf/Pe233v7t56QQJKEEECChZBgqIWV9qksLCy9u8QwUbbtDb+DRYigmAjgiKx0QQEDRKsJOpFo7e527djsUd0F/K1P+abmW8GomAwMMABlpYMRCgwWOPbiF7wDiBrCk0HExgO8AQBm7XIccjxnADywndaIhCd3U5Pl4DoWswuRANW9X2wzrYnMna8HyjSgz1XapWkY5s5+rhb03QSTA43y5erHGsqJdUkqk8TU0fqmNk1d/Vs/jMHMK6uqWDzNc+W+v3vs1OjUoKSGte5+8bXcousJ3e0Gq/JfCcBC57rO6qP7l55sqsHH0/TO8zWwUCQ7T9aa6mz8at/sVvUUslQLz9Mk/rLcxdf0G+6CaGU/EAUvFxT/bD82K28I5u1U7QeCNxL5UUc7TQyKHKG2e+JniGEec+5Eu6Xpb60N90PlFUnxkUCA9Znejs2G/4nh7ew+lnfLIAj0KHElW86vUFw0L5rYBjP6Y+0cx4y1/2IRS7sTnR9OUcgdmAxeqt6f8QRKmw4gmS5Ezg8R1eCl/aQfwFG/HlJxVV8BAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=28x28 at 0x7F2697573748>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open('pics/img_13.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABhklEQVR4nGWSvWqUURCGn5nz9/1sNlliGpGYYlOkslBsRJvFxkIskso7EBvBSxC09Qq8BW3sbBUECUiKFEoCUUFRVAyYTfJ9Y7FJds/ndIdn3pl5Zw5MI0RFImgEWJwhMcpJShJAcOiUqoOidFAqPgqQ6EZwgHMM6M+UBXVI7ZBUTDqInEIxgh2fvs4Nl999LGbqeYilw8+fv3z/1dHfZ3h/Bv0hi6NLRb06nA+F8toxoyRxxQ6sNfv99sn1GmDas/enSrev7uzvbe82EA9zE27t12ji253YP9uCi3anXmorFWha8blQFsaf1wBJZZQcscDDg0fTlYUObmwQ+4BPRdQcRbXvz7Wj8PSoEhGu3bP1Pt3owwW0R3ljM2WjaIKx8Il2H8Zfx3mziMPpSmAORkfLnaKOkvBmowK9u03dYQTC5pdVZPjzxcVcWOHp6U3bevrgQ7NCmdMkQPWyMfvxeJB/KhED1Ltbc7L3/lvnVAIgIU0Opek/hojQgGhDBwoYRLG2sXycf6s2VXZdK72IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=28x28 at 0x7F2697573EF0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open('pics/img_24.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving without dataset API\n",
    "\n",
    "Recommended when there is not much of preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/MNIST_DENSE/mnist_model.ckpt\n",
      "[4 5]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'models/MNIST_DENSE/mnist_model.ckpt')\n",
    "    sess.run(test_init_op)\n",
    "    \n",
    "    test_im1 = np.asarray(Image.open('pics/img_13.jpg')).reshape(1,28,28,1)\n",
    "    test_im2 = np.asarray(Image.open('pics/img_24.jpg')).reshape(1,28,28,1)\n",
    "    test_ims = np.concatenate((test_im1,test_im2),axis=0) #(2,28,28,1)\n",
    "    \n",
    "    predictions = tf.argmax(dense_net,axis=1)\n",
    "    out = sess.run(predictions,{is_serving:True,serving_input:test_ims})\n",
    "    \n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving with dataset API\n",
    "\n",
    "It is recommended to use dataset API whenever it is possible to match the dataset types and shapes with the training datasets\n",
    "\n",
    "Thus we can see that **reinitializable iterators** are useful when we want to fine tune the model on different dataset with different preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ims_paths = tf.placeholder(tf.string)\n",
    "serving_data = tf.data.Dataset.from_tensor_slices(test_ims_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(filepath):\n",
    "    image_string = tf.read_file(filepath)\n",
    "    image = tf.image.decode_jpeg(image_string)\n",
    "    image = tf.reshape(image,(28,28,1))\n",
    "    image = tf.image.convert_image_dtype(image,tf.float32)\n",
    "    return image\n",
    "    \n",
    "serving_data = serving_data.map(lambda x: read_img(x))\n",
    "serving_data = serving_data.map(lambda x: (x,tf.zeros((1,10)))) #To make output types match\n",
    "serving_data = serving_data.batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tf.float32, tf.float32),\n",
       " (TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(1)]),\n",
       "  TensorShape([Dimension(None), Dimension(1), Dimension(10)])))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_data.output_types,serving_data.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_init_op = iterator.make_initializer(serving_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/MNIST_DENSE/mnist_model.ckpt\n",
      "[4 5]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'models/MNIST_DENSE/mnist_model.ckpt')\n",
    "\n",
    "    ims_paths = ['pics/img_13.jpg','pics/img_24.jpg']\n",
    "    sess.run(serving_init_op,{test_ims_paths:ims_paths})\n",
    "    predictions = tf.argmax(dense_net,axis=1)\n",
    "    out = sess.run(predictions)\n",
    "    print(out)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "> 1) Do not use tf.int32 or int64 images while converting to float image. This scales float values close to 0\n",
    "\n",
    "> 2) We used **placeholder** to serve models, checking them with **if condition**. This increased training time by 2s for 60Kx10 images.\n",
    "\n",
    ">3) Although we dont use iterators while serving, one of the iterators had to be initialized.\n",
    "\n",
    ">4) **While reshaping tensors**, get batchsize with **tf.shape(tensor)[0]** instead of **tensor.shape[0]**. This is because the former returns a tensor, while the latter returns just a number\n",
    "\n",
    ">5) We looked into **arguments** of **tf.layers.Dense**. Familiarize with different kinds of regularizers and how to add them to loss function\n",
    "\n",
    ">6)  After training the model inside a session, SAVE IT. While evaluvating in a different session, we are not supposed to init global variables!. This will reset all weights!\n",
    "\n",
    ">7) Make a note of **resulting dimensions** of **tf.argmax**.\n",
    "```bash\n",
    "(10x1x10) ---> along axis 2 ---> (10x1)\n",
    "(10x10) ---> along axis 1 ---> 10\n",
    "```\n",
    "\n",
    ">8) While using **tf.equal** we have to keep the **broadcasting rule** in mind\n",
    "```bash\n",
    "labels:    10x1\n",
    "dense_net:   10\n",
    "tf.equal :   10x10 \n",
    "```\n",
    "Therefore, **transpose/reshape labels** to get the right dimension\n",
    "\n",
    ">9) **MOST IMPORTANT :** Dont create new tensors inside a loop! This will slow down everything\n",
    "\n",
    "> 10) We can see that **reinitializable iterators** are useful when we want to fine tune the model on different dataset with different preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
