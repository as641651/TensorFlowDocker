{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST CNN (LeNET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset reading pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('./datasets/MNIST_data/') \n",
    "train_images_path = p / 'train-images.idx3-ubyte'\n",
    "train_label_path = p / 'train-labels.idx1-ubyte'\n",
    "test_images_path = p / 't10k-images.idx3-ubyte'\n",
    "test_label_path = p / 't10k-labels.idx1-ubyte'\n",
    "\n",
    "def mnist_dataset(train:bool) -> tf.data.Dataset:\n",
    "    if train:\n",
    "        #4 byte offset for 4 numbers\n",
    "        im = tf.data.FixedLengthRecordDataset([str(train_images_path)],28*28,header_bytes=16)\n",
    "        #4 byte offset for 2 numbers\n",
    "        label = tf.data.FixedLengthRecordDataset([str(train_label_path)],1,header_bytes=8)        \n",
    "    else:\n",
    "        im = tf.data.FixedLengthRecordDataset([str(test_images_path)],28*28,header_bytes=16)\n",
    "        label = tf.data.FixedLengthRecordDataset([str(test_label_path)],1,header_bytes=8)\n",
    "        \n",
    "    im = im.map(lambda x: tf.decode_raw(x,tf.uint8),num_parallel_calls=4)\n",
    "    im = im.map(lambda x: tf.reshape(x,(28,28,1)),num_parallel_calls=4) \n",
    "    im = im.map(lambda x: tf.image.convert_image_dtype(x,tf.float32),num_parallel_calls=4)\n",
    "    im = im.map(lambda x: tf.image.resize_images(x,(32,32)))\n",
    "    \n",
    "    label = label.map(lambda x: tf.decode_raw(x,tf.uint8), num_parallel_calls=4)\n",
    "    label = label.map(lambda x: tf.one_hot(x,10), num_parallel_calls=4)\n",
    "    \n",
    "    dataset = tf.data.Dataset.zip((im,label))\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    train_dataset = mnist_dataset(True)\n",
    "    train_dataset = train_dataset.shuffle(20000)\n",
    "    train_dataset = train_dataset.repeat(10)\n",
    "    train_dataset = train_dataset.batch(10)\n",
    "    train_dataset = train_dataset.prefetch(2)\n",
    "    \n",
    "with tf.device('/cpu:0'):\n",
    "    test_dataset = mnist_dataset(False)\n",
    "    test_dataset = test_dataset.batch(10)\n",
    "    test_dataset = test_dataset.prefetch(2)\n",
    "    \n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types,train_dataset.output_shapes)\n",
    "model_input,label = iterator.get_next()\n",
    "\n",
    "training_init_op = iterator.make_initializer(train_dataset)\n",
    "test_init_op = iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(test_init_op)\n",
    "    i,l = sess.run([model_input,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 32, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f40185faf28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(i[0].reshape(32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LE-net\n",
    "\n",
    "<img src=\"pics/lenet.jpg\" width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating CNN output shape**: (Same folrmula applies for pooling too)\n",
    "\n",
    "> **out_W** = ((Width - Filter_W + 2xPadding)/stride_W) + 1\n",
    "\n",
    "> **out_H** = ((Height - Filter_H + 2xPadding)/stride_H) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(32), Dimension(32), Dimension(1)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolition 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(model_input,6,(5,5),(1,1),activation=tf.nn.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(test_init_op)\n",
    "    o = sess.run(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape #(32-5)/1. + 1 = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average pool 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpool1 = tf.layers.average_pooling2d(conv1,(2,2),(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14, 14, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(test_init_op)\n",
    "    o = sess.run(avgpool1)\n",
    "o.shape #(28-2)/2. + 1 = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = tf.layers.conv2d(avgpool1,16,(5,5),(1,1),activation=tf.nn.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(test_init_op)\n",
    "    o = sess.run(conv2)\n",
    "o.shape# (14-5)/1. + 1 = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average pool 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5, 5, 16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgpool2 = tf.layers.average_pooling2d(conv2,(2,2),(2,2))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(test_init_op)\n",
    "    o = sess.run(avgpool2)\n",
    "o.shape #(10-2)/2. + 1 = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 1, 120)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3 = tf.layers.conv2d(avgpool2,120,(5,5),(1,1),activation=tf.nn.tanh)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(test_init_op)\n",
    "    o = sess.run(conv3)\n",
    "o.shape #(5-5)/1. + 1 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flatten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 120)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = tf.layers.Flatten()(conv3)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(test_init_op)\n",
    "    o = sess.run(flatten)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_features(model_input):\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(model_input,6,(5,5),(1,1),activation=tf.nn.tanh)\n",
    "    avgpool1 = tf.layers.average_pooling2d(conv1,(2,2),(2,2))\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(avgpool1,16,(5,5),(1,1),activation=tf.nn.tanh)\n",
    "    avgpool2 = tf.layers.average_pooling2d(conv2,(2,2),(2,2))\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(avgpool2,120,(5,5),(1,1),activation=tf.nn.tanh)\n",
    "    \n",
    "    flatten = tf.layers.Flatten()(conv3)\n",
    "    \n",
    "    features = tf.layers.dense(flatten,84,activation=tf.nn.tanh)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 84)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = cnn_features(model_input)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(test_init_op)\n",
    "    o = sess.run(features)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier\n",
    "\n",
    "> We have the classifier separate, so that the features can be finetunes on some other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.layers.dense(features,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06158399, -0.00125845, -0.0380252 ,  0.0482185 ,  0.11377073,\n",
       "        -0.04729971,  0.03703606, -0.14200684,  0.02212132,  0.00433373],\n",
       "       [-0.0819338 ,  0.02448411, -0.10021084,  0.04427387,  0.06867027,\n",
       "        -0.07757335,  0.18205622, -0.04480159,  0.07955201,  0.10961425],\n",
       "       [ 0.05541191, -0.01347145, -0.04798395, -0.03188056,  0.09555981,\n",
       "         0.00900401,  0.10916211, -0.04232593, -0.04049245,  0.03779127],\n",
       "       [-0.12691906, -0.06379687, -0.05380139,  0.11359388,  0.13446128,\n",
       "        -0.10716493,  0.08703112, -0.14577502,  0.0660833 ,  0.02137068],\n",
       "       [-0.02304949,  0.05611792, -0.02910851,  0.11060248,  0.08766459,\n",
       "        -0.06275809, -0.00780628, -0.09804662,  0.08089873, -0.05021089],\n",
       "       [ 0.05454372, -0.01559561, -0.0602768 , -0.03158849,  0.13172951,\n",
       "        -0.01539958,  0.14186162, -0.0725493 , -0.03956236,  0.05747043],\n",
       "       [ 0.02804943,  0.10268132, -0.15091434,  0.03082578,  0.15652929,\n",
       "        -0.003925  , -0.00372341, -0.20401523,  0.01591226, -0.06387721],\n",
       "       [-0.09928472,  0.06920382,  0.05554977,  0.03734523,  0.17334953,\n",
       "        -0.08712371,  0.01485457, -0.1151662 ,  0.10144492,  0.0759143 ],\n",
       "       [ 0.02795822,  0.00264586, -0.04525377,  0.08958131,  0.09402416,\n",
       "        -0.05007758,  0.10518835, -0.12419745,  0.04962118, -0.05092819],\n",
       "       [-0.01447798,  0.01891256, -0.12853497,  0.05427183,  0.19009209,\n",
       "        -0.08240487,  0.05797452, -0.1158253 ,  0.00781473, -0.0151327 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(test_init_op)\n",
    "    o = sess.run(classifier)\n",
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label,logits=classifier))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm models/MNIST_CNN/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  5000 0.3912253\n",
      "Batch:  10000 0.15127452\n",
      "Batch:  15000 0.0963868\n",
      "Batch:  20000 0.07276272\n",
      "Batch:  25000 0.061499048\n",
      "Batch:  30000 0.05317923\n",
      "Batch:  35000 0.045373138\n",
      "Batch:  40000 0.040958915\n",
      "Batch:  45000 0.036442723\n",
      "Batch:  50000 0.03284309\n",
      "Batch:  55000 0.030515958\n",
      "Batch:  60000 0.02779906\n",
      "Elapsed time :  71.61451387405396  s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(training_init_op)\n",
    "\n",
    "    start = time.time()\n",
    "    try:\n",
    "        i = 1\n",
    "        tmp = []\n",
    "        while True:\n",
    "            i = i+1\n",
    "            l,_ = sess.run([loss,train])\n",
    "            tmp.append(l)\n",
    "            if i%5000 == 0:\n",
    "                avg_loss = np.array(tmp).mean()\n",
    "                print(\"Batch: \",i,avg_loss)\n",
    "                tmp = []\n",
    "                \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    print(\"Elapsed time : \", elapsed, \" s\")\n",
    "    saver.save(sess,'models/MNIST_CNN/mnist_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/MNIST_CNN/mnist_model.ckpt\n",
      "100 Mean Acc :  0.988\n",
      "200 Mean Acc :  0.97900003\n",
      "300 Mean Acc :  0.9779999\n",
      "400 Mean Acc :  0.99\n",
      "500 Mean Acc :  0.98100007\n",
      "600 Mean Acc :  0.995\n",
      "700 Mean Acc :  0.99\n",
      "800 Mean Acc :  0.998\n",
      "900 Mean Acc :  0.997\n",
      "1000 Mean Acc :  0.989\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(predict:'eg: [2,4,1,...]',true: 'eg: [2,4,1,...]') -> int:\n",
    "    correct_pred = tf.equal(predict,true)\n",
    "    #We have to cast [True,False,True,...] --> [1,0,1...]\n",
    "    acc = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "    return acc\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'models/MNIST_CNN/mnist_model.ckpt')\n",
    "    sess.run(test_init_op)\n",
    "    \n",
    "    #IMPORTANT:\n",
    "    #Dont place this code inside the loop! This will slow down everything\n",
    "    acc = get_accuracy(tf.argmax(classifier,axis=1),tf.transpose(tf.argmax(label,axis=2)))\n",
    "    \n",
    "    try:\n",
    "        i = 0\n",
    "        acc_list = []\n",
    "        while True:\n",
    "            i = i+1\n",
    "            a = sess.run(acc)\n",
    "            acc_list.append(a)\n",
    "            if i%100 == 0:\n",
    "                print(i, \"Mean Acc : \", np.array(acc_list).mean())\n",
    "                acc_list = []\n",
    "                           \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
