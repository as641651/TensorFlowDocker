{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10 Gray Finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches.meta.txt  data_batch_2.bin  data_batch_4.bin  readme.html\r\n",
      "data_batch_1.bin  data_batch_3.bin  data_batch_5.bin  test_batch.bin\r\n"
     ]
    }
   ],
   "source": [
    "ls datasets/cifar-10-batches-bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/cifar-10-batches-bin/data_batch_1.bin',\n",
       " 'datasets/cifar-10-batches-bin/data_batch_5.bin',\n",
       " 'datasets/cifar-10-batches-bin/data_batch_3.bin',\n",
       " 'datasets/cifar-10-batches-bin/data_batch_2.bin',\n",
       " 'datasets/cifar-10-batches-bin/data_batch_4.bin']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"datasets/cifar-10-batches-bin/data_batch_*\"\n",
    "train_bins = glob.glob(file_path)\n",
    "train_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR binary format\n",
    "\n",
    "```bash\n",
    "<1 byte x label><3*32*32 bytes x pixel>\n",
    "...\n",
    "<1 byte x label><3*32*32 bytes x pixel>\n",
    "```\n",
    "Each image is represented in **(C,H,W)** format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "ft = Path(train_bins[0]).open('rb')\n",
    "lbl = np.frombuffer(ft.read(1),np.dtype('u1'))\n",
    "print(lbl)\n",
    "img = np.frombuffer(ft.read(3*32*32),np.dtype('u1')).reshape(3,32,32)\n",
    "img = np.transpose(img,(1,2,0))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FC46C339AC8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FC5018C1860>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl = np.frombuffer(ft.read(1),np.dtype('u1'))\n",
    "img = np.frombuffer(ft.read(32*32*3),np.dtype('u1')).reshape(3,32,32)\n",
    "img = np.transpose(img,(1,2,0))\n",
    "print(lbl)\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR 10 dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_dataset(files_list:list) -> tf.data.Dataset:\n",
    "\n",
    "    data = tf.data.FixedLengthRecordDataset(files_list,1+3*32*32)\n",
    "    data = data.map(lambda x: tf.decode_raw(x,tf.uint8),num_parallel_calls=4)\n",
    "    data = data.map(lambda x: (x[1:],tf.expand_dims(x[0],0)),num_parallel_calls=4) #To match with MNIST\n",
    "    data = data.map(lambda x,y: (tf.reshape(x,(3,32,32)),y),num_parallel_calls=4)\n",
    "    data = data.map(lambda x,y: (tf.transpose(x,(1,2,0)),y),num_parallel_calls=4)\n",
    "    data = data.map(lambda x,y: (tf.image.rgb_to_grayscale(x),y),num_parallel_calls=4)\n",
    "    data = data.map(lambda x,y: (tf.image.convert_image_dtype(x,tf.float32),y),num_parallel_calls=4)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    train_dataset = cifar_dataset(train_bins)\n",
    "    train_dataset = train_dataset.shuffle(20000)\n",
    "    train_dataset = train_dataset.repeat(20)\n",
    "    train_dataset = train_dataset.batch(10)\n",
    "    train_dataset = train_dataset.prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorShape([Dimension(None), Dimension(32), Dimension(32), Dimension(1)]),\n",
       "  TensorShape([Dimension(None), Dimension(1)])),\n",
       " (tf.float32, tf.uint8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.output_shapes, train_dataset.output_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = train_dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check** (Restart kernel and dont call this check before training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "im,l = train_iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(train_iterator.initializer)\n",
    "    imr,lr = sess.run([im,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [8],\n",
       "       [1],\n",
       "       [6],\n",
       "       [1],\n",
       "       [5],\n",
       "       [6],\n",
       "       [3],\n",
       "       [8],\n",
       "       [4]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 32, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ef4018ac8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imr[0].reshape(32,32),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import inspect_checkpoint as chkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name:  Conv1/bias\n",
      "tensor_name:  Conv1/kernel\n",
      "tensor_name:  Conv2/bias\n",
      "tensor_name:  Conv2/kernel\n",
      "tensor_name:  Conv3/bias\n",
      "tensor_name:  Conv3/kernel\n",
      "tensor_name:  Dense_10/bias\n",
      "tensor_name:  Dense_10/kernel\n",
      "tensor_name:  Dense_84/bias\n",
      "tensor_name:  Dense_84/kernel\n"
     ]
    }
   ],
   "source": [
    "chkp.print_tensors_in_checkpoint_file('models/MNIST_CNN/mnist_model.ckpt',tensor_name='', all_tensors=False,all_tensor_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load graph\n",
    "\n",
    "> Calling **import_meta_data** adds all the variables to the default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph('models/MNIST_CNN/mnist_model.ckpt.meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Conv1/kernel:0' shape=(5, 5, 1, 6) dtype=float32_ref>,\n",
       " <tf.Variable 'Conv1/bias:0' shape=(6,) dtype=float32_ref>,\n",
       " <tf.Variable 'Conv2/kernel:0' shape=(5, 5, 6, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Conv2/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'Conv3/kernel:0' shape=(5, 5, 16, 120) dtype=float32_ref>,\n",
       " <tf.Variable 'Conv3/bias:0' shape=(120,) dtype=float32_ref>,\n",
       " <tf.Variable 'Dense_84/kernel:0' shape=(120, 84) dtype=float32_ref>,\n",
       " <tf.Variable 'Dense_84/bias:0' shape=(84,) dtype=float32_ref>,\n",
       " <tf.Variable 'Dense_10/kernel:0' shape=(84, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Dense_10/bias:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classifier', 'model_input', 'loss', 'variables', 'data_handle', 'target', 'train', 'train_op', 'trainable_variables', 'iterators']\n",
      "[<tf.Tensor 'Dense_10/BiasAdd:0' shape=(?, 10) dtype=float32>]\n",
      "[<tf.Tensor 'Placeholder:0' shape=() dtype=string>]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #saver.restore(sess,tf.train.latest_checkpoint('models/MNIST_CNN/'))\n",
    "    print(sess.graph.get_all_collection_keys())\n",
    "    print(sess.graph.get_collection('classifier'))\n",
    "    print(sess.graph.get_collection('data_handle'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check loading** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/MNIST_CNN/mnist_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('models/MNIST_CNN/'))\n",
    "    sess.run(train_iterator.initializer)\n",
    "    hdl = sess.run(train_iterator.string_handle())\n",
    "    out = sess.run(sess.graph.get_collection('classifier')[0],{sess.graph.get_collection('data_handle')[0]:hdl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.0189478 ,  -4.2664776 ,   3.5971777 ,   1.1141664 ,\n",
       "         -2.367669  ,  -5.1707683 ,  -0.50807637,  -5.4258213 ,\n",
       "         10.6410055 ,   1.9788061 ],\n",
       "       [  2.525255  ,  -4.3408823 ,  -0.8567331 ,   1.416412  ,\n",
       "         -5.978265  ,   5.3786383 ,   1.6240177 ,  -9.845654  ,\n",
       "          6.0208855 ,   1.4002415 ],\n",
       "       [  2.4485016 ,  -5.0073833 ,  -1.1253401 ,   2.2328122 ,\n",
       "         -2.3208823 ,  -0.5262407 ,  -0.8510316 ,  -9.240399  ,\n",
       "         11.391828  ,   2.8907218 ],\n",
       "       [  0.2218481 ,  -3.2344196 ,   0.5811044 ,  -1.1239905 ,\n",
       "         -0.5756186 ,   2.7580996 ,   7.7709365 , -13.409174  ,\n",
       "          7.724094  ,  -2.4644518 ],\n",
       "       [  7.118596  ,  -4.057072  ,   5.0432315 ,   0.60894734,\n",
       "         -3.9047565 ,  -0.9013839 ,   1.5265572 ,  -7.388623  ,\n",
       "          6.8964763 ,  -3.3079648 ],\n",
       "       [  4.3943677 ,  -4.572311  ,   1.7764732 ,   0.7551139 ,\n",
       "         -2.4600933 ,  -1.2062032 ,   2.5403178 , -10.603845  ,\n",
       "          9.449195  ,  -0.40938628],\n",
       "       [  3.9695783 ,  -4.149047  ,   1.471693  ,   0.78778034,\n",
       "         -2.3480775 ,  -0.3207467 ,   1.7691698 ,  -9.603303  ,\n",
       "         11.303334  ,  -0.811905  ],\n",
       "       [  3.000004  ,  -6.433831  ,   1.4901146 ,   3.6873097 ,\n",
       "         -3.8305905 ,  -3.9146023 ,  -1.7598982 ,  -3.4191327 ,\n",
       "          8.739144  ,   4.8652678 ],\n",
       "       [  1.7872187 ,  -4.7190895 ,   1.866745  ,   0.999911  ,\n",
       "         -0.89687085,  -1.7305975 ,   1.0281992 , -10.019808  ,\n",
       "         11.108979  ,   1.2143904 ],\n",
       "       [  5.610061  ,  -6.761235  ,   3.006925  ,  -2.38273   ,\n",
       "         -0.10269532,  -4.806787  ,  -0.02791733,  -3.3184783 ,\n",
       "          9.467517  ,   2.4297931 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm models/CIFAR10_grey/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/MNIST_CNN/mnist_model.ckpt\n",
      "Batch:  5000 2.0001802\n",
      "Batch:  10000 1.7430707\n",
      "Batch:  15000 1.6396687\n",
      "Batch:  20000 1.5670671\n",
      "Batch:  25000 1.5099636\n",
      "Batch:  30000 1.462484\n",
      "Batch:  35000 1.4191142\n",
      "Batch:  40000 1.3841664\n",
      "Batch:  45000 1.3517032\n",
      "Batch:  50000 1.3213867\n",
      "Batch:  55000 1.2926822\n",
      "Batch:  60000 1.2687166\n",
      "Batch:  65000 1.2451665\n",
      "Batch:  70000 1.2203715\n",
      "Batch:  75000 1.1963223\n",
      "Batch:  80000 1.1746683\n",
      "Batch:  85000 1.1517882\n",
      "Batch:  90000 1.1321872\n",
      "Batch:  95000 1.1118125\n",
      "Batch:  100000 1.0920491\n",
      "Elapsed time :  129.30929350852966  s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#Its better to use new saver, esp when you have created new tensors in this code\n",
    "saver_train = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('models/MNIST_CNN/'))\n",
    "    sess.run(train_iterator.initializer)\n",
    "    hdl = sess.run(train_iterator.string_handle())\n",
    "    \n",
    "    loss = sess.graph.get_collection('loss')[0]\n",
    "    train = sess.graph.get_collection('train')[0]\n",
    "    handle = sess.graph.get_collection('data_handle')[0]\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    try:\n",
    "        i = 1\n",
    "        tmp = []\n",
    "        while True:\n",
    "            i = i+1\n",
    "            l,_ = sess.run([loss,train],{handle:hdl})\n",
    "            tmp.append(l)\n",
    "            if i%5000 == 0:\n",
    "                avg_loss = np.array(tmp).mean()\n",
    "                print(\"Batch: \",i,avg_loss)\n",
    "                tmp = []\n",
    "                \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    print(\"Elapsed time : \", elapsed, \" s\")\n",
    "    \n",
    "    \n",
    "    saver_train.save(sess,'models/CIFAR10_grey/cifar_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    test_dataset = cifar_dataset(['datasets/cifar-10-batches-bin/test_batch.bin'])\n",
    "    test_dataset = test_dataset.batch(10)\n",
    "    test_dataset = test_dataset.prefetch(2)\n",
    "    \n",
    "test_iterator = test_dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/CIFAR10_grey/cifar_model.ckpt\n",
      "100 Mean Acc :  0.53099996\n",
      "200 Mean Acc :  0.535\n",
      "300 Mean Acc :  0.51500005\n",
      "400 Mean Acc :  0.536\n",
      "500 Mean Acc :  0.546\n",
      "600 Mean Acc :  0.55\n",
      "700 Mean Acc :  0.525\n",
      "800 Mean Acc :  0.53400004\n",
      "900 Mean Acc :  0.50499994\n",
      "1000 Mean Acc :  0.523\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(predict:'eg: [2,4,1,...]',true: 'eg: [2,4,1,...]') -> int:\n",
    "    correct_pred = tf.equal(predict,true)\n",
    "    #We have to cast [True,False,True,...] --> [1,0,1...]\n",
    "    acc = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "    return acc\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    saver_train.restore(sess,'models/CIFAR10_grey/cifar_model.ckpt')\n",
    "    sess.run(test_iterator.initializer)\n",
    "    hdl = sess.run(test_iterator.string_handle())\n",
    "\n",
    "    \n",
    "    label = sess.graph.get_collection('target')[0]\n",
    "    classifier = sess.graph.get_collection('classifier')[0]\n",
    "    handle = sess.graph.get_collection('data_handle')[0]\n",
    "    \n",
    "    #IMPORTANT:\n",
    "    #Dont place this code inside the loop! This will slow down everything\n",
    "    acc = get_accuracy(tf.argmax(classifier,axis=1),tf.transpose(tf.argmax(tf.one_hot(label,10),axis=2)))\n",
    "    \n",
    "    try:\n",
    "        i = 0\n",
    "        acc_list = []\n",
    "        while True:\n",
    "            i = i+1\n",
    "            a = sess.run(acc,{handle:hdl})\n",
    "            acc_list.append(a)\n",
    "            if i%100 == 0:\n",
    "                print(i, \"Mean Acc : \", np.array(acc_list).mean())\n",
    "                acc_list = []\n",
    "                           \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LeNET from scratch (Not much difference)\n",
    "\n",
    "> Just add **tf.global_variable_initializer** to the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm models/CIFAR10_grey/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/MNIST_CNN/mnist_model.ckpt\n",
      "Batch:  5000 2.0937455\n",
      "Batch:  10000 1.8949004\n",
      "Batch:  15000 1.7356673\n",
      "Batch:  20000 1.648246\n",
      "Batch:  25000 1.5810332\n",
      "Batch:  30000 1.5213076\n",
      "Batch:  35000 1.4676836\n",
      "Batch:  40000 1.4214152\n",
      "Batch:  45000 1.3797578\n",
      "Batch:  50000 1.3418465\n",
      "Batch:  55000 1.3089824\n",
      "Batch:  60000 1.2737926\n",
      "Batch:  65000 1.2469199\n",
      "Batch:  70000 1.2171801\n",
      "Batch:  75000 1.1889061\n",
      "Batch:  80000 1.1639483\n",
      "Batch:  85000 1.1366851\n",
      "Batch:  90000 1.1154944\n",
      "Batch:  95000 1.0912582\n",
      "Batch:  100000 1.0679497\n",
      "Elapsed time :  131.02445888519287  s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#saver = tf.train.import_meta_graph('models/MNIST_CNN/mnist_model.ckpt.meta')\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('models/MNIST_CNN/'))\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    sess.run(train_iterator.initializer)\n",
    "    hdl = sess.run(train_iterator.string_handle())\n",
    "    \n",
    "    loss = sess.graph.get_collection('loss')[0]\n",
    "    train = sess.graph.get_collection('train')[0]\n",
    "    handle = sess.graph.get_collection('data_handle')[0]\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    try:\n",
    "        i = 1\n",
    "        tmp = []\n",
    "        while True:\n",
    "            i = i+1\n",
    "            l,_ = sess.run([loss,train],{handle:hdl})\n",
    "            tmp.append(l)\n",
    "            if i%5000 == 0:\n",
    "                avg_loss = np.array(tmp).mean()\n",
    "                print(\"Batch: \",i,avg_loss)\n",
    "                tmp = []\n",
    "                \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    print(\"Elapsed time : \", elapsed, \" s\")\n",
    "    \n",
    "    \n",
    "    saver.save(sess,'models/CIFAR10_grey/cifar_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/CIFAR10_grey/cifar_model.ckpt\n",
      "100 Mean Acc :  0.543\n",
      "200 Mean Acc :  0.523\n",
      "300 Mean Acc :  0.53199995\n",
      "400 Mean Acc :  0.536\n",
      "500 Mean Acc :  0.56399995\n",
      "600 Mean Acc :  0.515\n",
      "700 Mean Acc :  0.49300003\n",
      "800 Mean Acc :  0.53999996\n",
      "900 Mean Acc :  0.51\n",
      "1000 Mean Acc :  0.52900004\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'models/CIFAR10_grey/cifar_model.ckpt')\n",
    "    #sess.run(tf.global_variables_initializer()) #0.01 acc for non trained model\n",
    "    sess.run(test_iterator.initializer)\n",
    "    hdl = sess.run(test_iterator.string_handle())\n",
    "    \n",
    "    label = sess.graph.get_collection('target')[0]\n",
    "    classifier = sess.graph.get_collection('classifier')[0]\n",
    "    \n",
    "    #IMPORTANT:\n",
    "    #Dont place this code inside the loop! This will slow down everything\n",
    "    acc = get_accuracy(tf.argmax(classifier,axis=1),tf.transpose(tf.argmax(tf.one_hot(label,10),axis=2)))\n",
    "    \n",
    "    try:\n",
    "        i = 0\n",
    "        acc_list = []\n",
    "        while True:\n",
    "            i = i+1\n",
    "            a = sess.run(acc,{handle:hdl})\n",
    "            acc_list.append(a)\n",
    "            if i%100 == 0:\n",
    "                print(i, \"Mean Acc : \", np.array(acc_list).mean())\n",
    "                acc_list = []\n",
    "                           \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**IMPORTANT**: \n",
    "\n",
    "> 1) Do not call **get_next** of any child iterators, when using **feedable iterators**. Make sure they are not called before taining\n",
    "\n",
    "> 2) Calling **import_meta_data** adds all the variables to the default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
